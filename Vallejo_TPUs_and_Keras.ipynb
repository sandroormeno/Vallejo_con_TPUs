{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vallejo TPUs and Keras",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sandroormeno/Vallejo_con_TPUs/blob/master/Vallejo_TPUs_and_Keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bfJp0Q0M1npS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "metadata": {
        "id": "rxkNIKFM1vWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "edfbxDDh2AEs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predict Shakespeare with Cloud TPUs and Keras"
      ]
    },
    {
      "metadata": {
        "id": "wYp6XVQU2POn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/tpu/blob/master/tools/colab/shakespeare_with_tpu_and_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "xzpUtDMqmA-x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This example uses [tf.keras](https://www.tensorflow.org/guide/keras) to build a *language model* and train it on a [Google Cloud TPU](https://cloud.google.com/tpu/). This language model predicts the next character of text given the text so far. The trained model can generate new snippets of text that read in a similar style to the text training data.\n",
        "\n",
        "We'll train the model on the combined works of William Shakespeare, then use it to compose a play in the style of *The Great Bard*:\n",
        "\n",
        "<blockquote>\n",
        "Loves that led me no dumbs lack her Berjoy's face with her to-day.  \n",
        "The spirits roar'd; which shames which within his powers  \n",
        "\tWhich tied up remedies lending with occasion,  \n",
        "A loud and Lancaster, stabb'd in me  \n",
        "\tUpon my sword for ever: 'Agripo'er, his days let me free.  \n",
        "\tStop it of that word, be so: at Lear,  \n",
        "\tWhen I did profess the hour-stranger for my life,  \n",
        "\tWhen I did sink to be cried how for aught;  \n",
        "\tSome beds which seeks chaste senses prove burning;  \n",
        "But he perforces seen in her eyes so fast;  \n",
        "And _    \n",
        "</blockquote>\n",
        "\n",
        "Note: To enable TPUs on Google Colab, select *Runtime > Change runtime type*, and set *Hardware acceleration* to TPU."
      ]
    },
    {
      "metadata": {
        "id": "KRQ6Fjra3Ruq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download data\n",
        "\n",
        "Download *The Complete Works of William Shakespeare* as a single text file from [Project Gutenberg](https://www.gutenberg.org/). We'll use snippets from this file as the *training data* for the model. The *target* snippet is offset by one character."
      ]
    },
    {
      "metadata": {
        "id": "j8sIXh1DEDDd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9640b5a9-6064-4f1c-d9be-7dd5d5722c98"
      },
      "cell_type": "code",
      "source": [
        "!wget --show-progress --continue -O /content/vallejo.txt https://raw.githubusercontent.com/sandroormeno/Vallejo_con_TPUs/master/data/vallejo.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.1’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AbL6cqCl7hnt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build the data generator"
      ]
    },
    {
      "metadata": {
        "id": "E3V4V-Jxmuv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a809190e-db3d-42b1-e15b-60dae9dfed38"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import six\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "SHAKESPEARE_TXT = '/content/vallejo.txt'\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "def transform(txt, pad_to=None):\n",
        "  # drop any non-ascii characters\n",
        "  output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
        "  if pad_to is not None:\n",
        "    output = output[:pad_to]\n",
        "    output = np.concatenate([\n",
        "        np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
        "        output,\n",
        "    ])\n",
        "  return output\n",
        "\n",
        "def training_generator(seq_len=100, batch_size=1024):\n",
        "  \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
        "  with tf.gfile.GFile(SHAKESPEARE_TXT, 'r') as f:\n",
        "    txt = f.read()\n",
        "\n",
        "  tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
        "  source = transform(txt)\n",
        "  while True:\n",
        "    offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
        "\n",
        "    # Our model uses sparse crossentropy loss, but Keras requires labels\n",
        "    # to have the same rank as the input logits.  We add an empty final\n",
        "    # dimension to account for this.\n",
        "    yield (\n",
        "        np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
        "        np.expand_dims(\n",
        "            np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]),\n",
        "            -1),\n",
        "    )\n",
        "\n",
        "six.next(training_generator(seq_len=10, batch_size=1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Input text [250593] ﻿\r\n",
            "\r\n",
            "Los Heraldos Negros\r\n",
            "(1918)\r\n",
            "\r\n",
            "\r\n",
            "LOS HERALDOS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[110, 100, 111,  46,  46,  46,  13,  10,  13,  10]], dtype=int32),\n",
              " array([[[100],\n",
              "         [111],\n",
              "         [ 46],\n",
              "         [ 46],\n",
              "         [ 46],\n",
              "         [ 13],\n",
              "         [ 10],\n",
              "         [ 13],\n",
              "         [ 10],\n",
              "         [ 68]]], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Bbb05dNynDrQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "The model is defined as a two-layer, forward-LSTM—with two changes from the `tf.keras` standard LSTM definition:\n",
        "\n",
        "1. Define the input `shape` of our model which satisfies the [XLA compiler](https://www.tensorflow.org/performance/xla/)'s static shape requirement.\n",
        "2. Use `tf.train.Optimizer` instead of a standard Keras optimizer (Keras optimizer support is still experimental)."
      ]
    },
    {
      "metadata": {
        "id": "yLEM-fLJlEEt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "  \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
        "  source = tf.keras.Input(\n",
        "      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
        "  model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
        "  model.compile(\n",
        "      optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VzBYDJI0_Tfm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "The `tf.contrib.tpu.keras_to_tpu_model` function converts a `tf.keras` model to an equivalent TPU version. We then use the standard Keras methods to train: `fit`, `predict`, and `evaluate`."
      ]
    },
    {
      "metadata": {
        "id": "ExQ922tfzSGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "37c3451c-e01a-4e3a-fbde-76b2b9c90581"
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "training_model = lstm_model(seq_len=100, batch_size=128, stateful=False)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    training_model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "tpu_model.fit_generator(\n",
        "    training_generator(seq_len=100, batch_size=1024),\n",
        "    steps_per_epoch=100,\n",
        "    epochs=10,\n",
        ")\n",
        "tpu_model.save_weights('/tmp/bard.h5', overwrite=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.99.189.98:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 8869711600961521496)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 212061580876133003)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 2690410430993031016)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7427259642736647781)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5974654814982514243)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12175354480154809496)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4560449559285082905)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6958338485208868126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12559433668596278516)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 15928701053319996949)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6266601347043838844)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13607303928733081498)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:Input text [250593] ﻿\n",
            "\n",
            "Los Heraldos Negros\n",
            "(1918)\n",
            "\n",
            "\n",
            "LOS HERALDOS\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(128, 100), dtype=tf.int32, name='seed0'), TensorSpec(shape=(128, 100, 1), dtype=tf.float32, name='time_distributed_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for seed\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.671211242675781 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "100/100 [==============================] - 26s 258ms/step - loss: 4.4915 - sparse_categorical_accuracy: 0.1417\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 3.0977 - sparse_categorical_accuracy: 0.1683\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 1.9957 - sparse_categorical_accuracy: 0.3847\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 1.2053 - sparse_categorical_accuracy: 0.6148\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.8344\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.3053 - sparse_categorical_accuracy: 0.9114\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.2482 - sparse_categorical_accuracy: 0.9274\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9342\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.2090 - sparse_categorical_accuracy: 0.9377\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.1942 - sparse_categorical_accuracy: 0.9420\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TCBtcpZkykSf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make predictions with the model\n",
        "\n",
        "Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
        "Start the model off with a *seed* sentence, then generate 250 characters from it. We'll make five predictions from the initial seed."
      ]
    },
    {
      "metadata": {
        "id": "tU7M-EGGxR3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        },
        "outputId": "a726cf56-bf2d-4f5a-b543-1575bbf4001e"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 5\n",
        "PREDICT_LEN = 250\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/tmp/bard.h5')\n",
        "\n",
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "\n",
        "seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "\n",
        "# First, run the seed forward to prime the state of the model.\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])\n",
        "\n",
        "# Now we can accumulate predictions!\n",
        "predictions = [seed[:, -1:]]\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
        "  \n",
        "  # sample from our output distribution\n",
        "  next_idx = [\n",
        "      np.random.choice(256, p=next_probits[i])\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "  \n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "  print('PREDICTION %d\\n\\n' % i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  generated = ''.join([chr(c) for c in p])\n",
        "  print(generated)\n",
        "  print()\n",
        "  assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION 0\n",
            "\n",
            "\n",
            " Mi madre rece\r\n",
            "en infante es el resplandor,\r\n",
            "y en el andar de ese instante, la gala\r\n",
            "desnuda tu espacia de un suerte?\r\n",
            "¡césar Valeroso, yo no avanzo.\r\n",
            "Rubio y triste esqueleto.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Un hombre está en su mano\r\n",
            "la estrella de la tarde azul destorada\n",
            "\n",
            "PREDICTION 1\n",
            "\n",
            "\n",
            " Mi hermana de este hombre, se refugia, para traduada de durar.\r\n",
            "Antes a sus destinos,\r\n",
            "de esperar esperanzas en la mesa\r\n",
            "ese mayor buena, a Goya, de oyendo;\r\n",
            "aún la metración de sangre a flor de cuerda en una esquina coloración.\r\n",
            "\r\n",
            "\r\n",
            "Poemas en este \n",
            "\n",
            "PREDICTION 2\n",
            "\n",
            "\n",
            " Sólo al dejar de dos en dos flautas\r\n",
            "de nuevo. ¿Cuándo, en efecto, le cara a la mesa dire: en miempo a después de tantas palabras,\r\n",
            "se encenderán mi llave, la quererla en esa amema duerme entre nosotros, aquí,\r\n",
            "vaporíamente a veces aquesos de mostad\n",
            "\n",
            "PREDICTION 3\n",
            "\n",
            "\n",
            " Mi hermana ecciagueando habrá ahora de mí, de mi sufrimiento, este día\r\n",
            "es la madre desnudo,\r\n",
            "                        ni van ni vienen.\r\n",
            "\r\n",
            "      Las uñas. Apeo lo que se deja en la majana menor dos pechos\r\n",
            "y la muerte de estas nacias\r\n",
            "(a qué hacer s\n",
            "\n",
            "PREDICTION 4\n",
            "\n",
            "\n",
            " Mi esperanza y revuelve,\r\n",
            "a un nido de esperar en zapatillas,\r\n",
            "de esperar el sol en el tante;\r\n",
            "¿di, mamá?\r\n",
            "\r\n",
            "\r\n",
            "XXIV\r\n",
            "Al borde de un sepulcro florecido\r\n",
            "transcurrendar, desde el mismos en es\ra este borde viejo ducha.\r\n",
            "\r\n",
            "      O sin madre, sin amada, \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}